{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c8586d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d3f397b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir=r'dataaset\\images'\n",
    "mask_dir=r'dataaset\\masks'\n",
    "\n",
    "image_size = (224, 224)\n",
    "num_classes = 3\n",
    "batch_size=2\n",
    "epochs=10\n",
    "\n",
    "image_paths = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir)])\n",
    "mask_paths = sorted([os.path.join(mask_dir, f) for f in os.listdir(mask_dir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "905adeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs: 109\n"
     ]
    }
   ],
   "source": [
    "image_paths = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir)])\n",
    "mask_paths = sorted([os.path.join(mask_dir, f) for f in os.listdir(mask_dir)])\n",
    "\n",
    "assert len(image_paths) == len(mask_paths), \"Mismatch in number of images and masks\"\n",
    "print(\"Total pairs:\", len(image_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d94be550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess(image_path, mask_path):\n",
    "    # Load and resize image\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    image = tf.image.resize(image, image_size)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "\n",
    "    # Load and resize mask\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    mask = tf.image.decode_png(mask, channels=1)  # Force 1 channel\n",
    "    mask = tf.image.resize(mask,image_size, method='nearest')\n",
    "    mask = tf.squeeze(mask, axis=-1)              # Remove channel\n",
    "    mask = tf.cast(mask, tf.int32)                # For sparse_categorical_crossentropy\n",
    "\n",
    "    return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1b190b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((image_paths, mask_paths))\n",
    "dataset = dataset.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "dataset = dataset.cache().shuffle(buffer_size=100)\n",
    "train_ds = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "589fc8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Image batch shape: (2, 224, 224, 3)\n",
      "ðŸ§ª Mask batch shape: (2, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "for batch_images, batch_masks in train_ds.take(1):\n",
    "    print(\"ðŸ§ª Image batch shape:\", batch_images.shape)\n",
    "    print(\"ðŸ§ª Mask batch shape:\", batch_masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20a27ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_fake_dataset(batch_size=2, img_size=(256, 256), num_classes=3):\n",
    "#     def gen():\n",
    "#         for _ in range(100):\n",
    "#             img = tf.random.uniform((img_size[0], img_size[1], 3), dtype=tf.float32)\n",
    "#             mask = tf.random.uniform((img_size[0], img_size[1]), maxval=num_classes, dtype=tf.int32)\n",
    "#             yield img, mask\n",
    "\n",
    "#     dataset = tf.data.Dataset.from_generator(\n",
    "#         gen,\n",
    "#         output_signature=(\n",
    "#             tf.TensorSpec(shape=(256, 256, 3), dtype=tf.float32),\n",
    "#             tf.TensorSpec(shape=(256, 256), dtype=tf.int32)\n",
    "#         )\n",
    "#     )\n",
    "#     return dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# fake_train = generate_fake_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6bea8933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_block(filters,kernel_size):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2DTranspose(filters,kernel_size,strides=2,padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.ReLU()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e39b97e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet_mobilenetv2(input_shape, num_classes):\n",
    "    base_model = tf.keras.applications.MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "\n",
    "    # Use intermediate layers for skip connections\n",
    "    layer_names = [\n",
    "        'block_1_expand_relu',   # 112x112\n",
    "        'block_3_expand_relu',   # 56x56\n",
    "        'block_6_expand_relu',   # 28x28\n",
    "        'block_13_expand_relu',  # 14x14\n",
    "        'out_relu'               # 7x7\n",
    "    ]\n",
    "    layers = [base_model.get_layer(name).output for name in layer_names]\n",
    "\n",
    "    down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
    "    down_stack.trainable = True  # Enable fine-tuning\n",
    "\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    skips = down_stack(inputs)\n",
    "    x = skips[-1]  # Start from 'out_relu' (7x7)\n",
    "\n",
    "    # Decoder: upsampling and concatenation with skip connections\n",
    "    x = upsample_block(512, 3)(x)           # 14x14\n",
    "    x = tf.keras.layers.Concatenate()([x, skips[-2]])\n",
    "\n",
    "    x = upsample_block(256, 3)(x)           # 28x28\n",
    "    x = tf.keras.layers.Concatenate()([x, skips[-3]])\n",
    "\n",
    "    x = upsample_block(128, 3)(x)           # 56x56\n",
    "    x = tf.keras.layers.Concatenate()([x, skips[-4]])\n",
    "\n",
    "    x = upsample_block(64, 3)(x)            # 112x112\n",
    "    x = tf.keras.layers.Concatenate()([x, skips[-5]])\n",
    "\n",
    "    x = upsample_block(32, 3)(x)            # 224x224\n",
    "\n",
    "    # Final segmentation head\n",
    "    outputs = tf.keras.layers.Conv2D(num_classes, 1, activation='softmax')(x)\n",
    "\n",
    "    return tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "423407ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " model_6 (Functional)        [(None, 112, 112, 96),       2257984   ['input_8[0][0]']             \n",
      "                              (None, 56, 56, 144),                                                \n",
      "                              (None, 28, 28, 192),                                                \n",
      "                              (None, 14, 14, 576),                                                \n",
      "                              (None, 7, 7, 1280)]                                                 \n",
      "                                                                                                  \n",
      " sequential_15 (Sequential)  (None, 14, 14, 512)          5900800   ['model_6[0][4]']             \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 14, 14, 1088)         0         ['sequential_15[0][0]',       \n",
      " )                                                                   'model_6[0][3]']             \n",
      "                                                                                                  \n",
      " sequential_16 (Sequential)  (None, 28, 28, 256)          2508032   ['concatenate_4[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, 28, 28, 448)          0         ['sequential_16[0][0]',       \n",
      " )                                                                   'model_6[0][2]']             \n",
      "                                                                                                  \n",
      " sequential_17 (Sequential)  (None, 56, 56, 128)          516736    ['concatenate_5[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate  (None, 56, 56, 272)          0         ['sequential_17[0][0]',       \n",
      " )                                                                   'model_6[0][1]']             \n",
      "                                                                                                  \n",
      " sequential_18 (Sequential)  (None, 112, 112, 64)         156992    ['concatenate_6[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate  (None, 112, 112, 160)        0         ['sequential_18[0][0]',       \n",
      " )                                                                   'model_6[0][0]']             \n",
      "                                                                                                  \n",
      " sequential_19 (Sequential)  (None, 224, 224, 32)         46240     ['concatenate_7[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 224, 224, 3)          99        ['sequential_19[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11386883 (43.44 MB)\n",
      "Trainable params: 11350787 (43.30 MB)\n",
      "Non-trainable params: 36096 (141.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_unet_mobilenetv2(image_size + (3,), num_classes)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c0283c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 66s 934ms/step - loss: 0.6854 - accuracy: 0.7046\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 47s 860ms/step - loss: 0.4104 - accuracy: 0.8310\n",
      "Epoch 3/10\n",
      "49/55 [=========================>....] - ETA: 5s - loss: 0.3462 - accuracy: 0.8557"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43104e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
